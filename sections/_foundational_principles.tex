The GASing method is built upon several coherent principles designed to simplify arithmetic into a minimal set of understandable and computationally efficient operations. These principles collectively support the goal of grounding all arithmetic in addition, thereby clarifying resource consumption and enhancing the interpretability of reasoning processes.
\subsubsection{2.1 The Digit-Wise Processing Paradigm}

At its core, GASing employs a digit-wise processing approach that, instead of merely breaking numbers into fixed constituent digits, flexibly defines the boundaries of arithmetic operations by utilizing the topological properties of Carry and Borrow propagations between adjacent numerical segments (or 'digits'). The granularity of these segments can be dynamically determined to optimize arithmetic calculation efficiency, particularly leveraging the observation that operations become highly efficient when all unique combinations of numerical values within these segments can be assessed \emph{a priori}. This refined digit-wise paradigm is fundamental to minimizing the complexity of the operational vocabulary. Instead of treating numbers as holistic entities requiring a potentially tedious array of complex operations, GASing focuses on manipulating these individual segments using a very limited set of rules, primarily those governing the foundational principles of addition applied at the segment level. This approach aligns with both human cognitive abilities and computational architecture:

- \textbf{Human Cognition}: By processing operations at the level of these flexibly defined numerical segments (which can be as small as single digits), GASing leverages established neural pathways for simpler operations (Dehaene, 2011). This modular, segment-based processing keeps the cognitive load for each step manageable, making the system intuitive and easier for human users to verify, even as the definition of a 'segment' adapts for efficiency.
- \textbf{Computational Architecture}: This segment-wise processing, where segments can be optimized for computational efficiency (e.g., to fit register sizes or leverage pre-computed lookup tables for segment-level operations), maps effectively to modern processor capabilities. Reducing operations to their simplest form at the segment level (e.g., segment addition and inter-segment carry/borrow) allows for granular understanding, control of computational resources, and potential for optimized hardware implementations.

This fine-grained processing is key to building complex operations from the simplest possible base, ensuring that the entire system remains transparent and its resource demands predictable.
\subsubsection{2.2 Modular Operation Design: A Minimal Vocabulary Anchored in Addition}

GASing builds all arithmetic operations as modular extensions of one another, with \textbf{addition, applied at the level of flexibly defined numerical segments, serving as the single, foundational operator}. This hierarchical construction, leveraging the segment-wise processing described earlier, is central to achieving a minimal operational vocabulary and directly impacts the assessment of resource consumption:

1.  \textbf{Segment-wise Addition} serves as the foundational, irreducible operation. All other arithmetic operations are defined in terms of sequences or transformations of this fundamental segment-wise addition, including the management of carry and borrow propagations between segments.
2.  \textbf{Multiplication} is constructed as specialized, repeated segment-wise addition. The process involves systematic application of segment-level additions and accumulation of partial results, explicitly defining multiplication's resource cost in terms of the underlying additive operations on segments.
3.  \textbf{Subtraction} is implemented as segment-wise addition using complementary segment values (e.g., employing ten's complement for decimal segments or two's complement for binary segments). This reframes subtraction entirely within the additive framework at the segment level, maintaining the minimal operational vocabulary.
4.  \textbf{Division} is approached through repeated segment-wise subtraction (which, as noted, is itself addition-based) with optimizations that can leverage pattern recognition across segments. Its complexity and resource use are, therefore, also traceable back to the fundamental segment-wise addition operations.

This modularity, centered on segment-wise addition, creates a coherent and parsimonious framework. Mastery of segment-wise addition directly facilitates the understanding and implementation of all other operations. More importantly, it means that the entire arithmetic system can be analyzed, and its resource consumption (both cognitive and computational) can be estimated based on the number and type of segment-wise addition-equivalent steps involved. This contrasts sharply with systems where each operator might be a black box with unique, opaque resource demands, and it aligns with the goal of transparently assessing computational effort by reducing all operations to a common, addition-based denominator at a flexible granularity.
\subsubsection{2.3 Lookup Tables and Pattern Recognition: Optimizing the Core Operator}

Central to the GASing method is the use of precomputed lookup tables for basic operations, \textbf{particularly for single-digit addition and its immediate consequences (like carry generation)}. These tables are not an expansion of the operational vocabulary but rather an optimization strategy for the core addition operator:

-   \textbf{Reduce Cognitive and Computational Load}: By pre-calculating and storing the results of all possible single-digit additions (e.g., 0+0 through 9+9), the need for real-time calculation of these base operations is eliminated. This directly speeds up the execution of the foundational operator.
-   \textbf{Enable Pattern Recognition}: Consistent use of lookup tables for the core additive step allows for the easier identification of recurring patterns across multiple calculations. This can lead to higher-level optimizations and a better understanding of the computational structure of a problem, all while still operating within an addition-centric framework.
-   \textbf{Analogous to Caching}: These tables function similarly to CPU cache mechanisms or memoization in computing systems, storing frequently accessed results to avoid redundant computation. This makes the core addition process highly efficient.

By optimizing the execution of the single core operator (addition) through lookup tables, GASing ensures that the minimal vocabulary does not come at the cost of prohibitive inefficiency for elementary steps. This focus on optimizing the fundamental building block is crucial for the scalability and practicality of the approach, ensuring that even complex reasoning built from these simple steps remains manageable in terms of resource consumption.
